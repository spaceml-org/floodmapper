{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202abce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary imports\n",
    "import os\n",
    "import pathlib\n",
    "os.environ['USE_PYGEOS'] = '0'\n",
    "import gc\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "from datetime import datetime\n",
    "from zoneinfo import ZoneInfo\n",
    "from dotenv import load_dotenv\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors\n",
    "import ee\n",
    "\n",
    "import pandas as pd\n",
    "from georeader.readers import ee_query\n",
    "import folium\n",
    "import geemap.foliumap as geemap\n",
    "import shapely\n",
    "from shapely.geometry import box, Point, MultiPoint\n",
    "from shapely.ops import nearest_points\n",
    "\n",
    "from skimage.morphology import binary_dilation, disk\n",
    "\n",
    "from typing import Tuple, Callable, Any, Optional\n",
    "\n",
    "\n",
    "from ml4floods.data.worldfloods import dataset\n",
    "from ml4floods.data import utils\n",
    "from ml4floods.visualization import plot_utils\n",
    "from ml4floods.models import postprocess\n",
    "\n",
    "from db_utils import DB\n",
    "\n",
    "# Uncomment this to suppress deprecation warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "from shapely.errors import ShapelyDeprecationWarning\n",
    "warnings.filterwarnings(\"ignore\", category=ShapelyDeprecationWarning) \n",
    "\n",
    "# Set bucket will not be requester pays\n",
    "utils.REQUESTER_PAYS_DEFAULT = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de44e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "from rasterio.io import MemoryFile\n",
    "from rasterio import Affine as A\n",
    "from rasterio import CRS\n",
    "#from rasterio.warp import reproject, Resampling\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "from rasterio.transform import from_origin\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c10a43c",
   "metadata": {},
   "source": [
    "## Load environment and project details\n",
    "\n",
    "As with the other notebooks, we load credentials and project details from a hidden ```.env``` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddff7ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables (including path to credentials) from '.env' file\n",
    "env_file_path = \"../.env\"\n",
    "\n",
    "# Uncomment for alternative version for Windows (r\"\" indicates raw string)\n",
    "#env_file_path = r\"C:/Users/User/floodmapper/.env\"\n",
    "\n",
    "assert load_dotenv(dotenv_path=env_file_path) == True, \"[ERR] failed to load environment!\"\n",
    "assert \"GOOGLE_APPLICATION_CREDENTIALS\" in os.environ, \"[ERR] missing $GOOGLE_APPLICATION_CREDENTIAL!\"\n",
    "assert \"GS_USER_PROJECT\" in os.environ, \"[ERR] missing $GS_USER_PROJECT!\"\n",
    "key_file_path = os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]\n",
    "assert os.path.exists(key_file_path), f\"[ERR] Google credential key file does not exist: \\n{key_file_path} \"\n",
    "assert \"ML4FLOODS_BASE_DIR\" in os.environ, \"[ERR] missing $ML4FLOODS_BASE_DIR!\"\n",
    "base_path = os.environ[\"ML4FLOODS_BASE_DIR\"]\n",
    "assert os.path.exists(base_path), f\"[ERR] base path does not exist: \\n{base_path} \"\n",
    "bucket_name = os.environ[\"BUCKET_URI\"]\n",
    "assert bucket_name is not None and bucket_name != \"\", f\"Bucket name not defined {bucket_name}\"\n",
    "\n",
    "print(\"[INFO] Successfully loaded FloodMapper environment.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc803fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the database (point to the .env file for credentials)\n",
    "db_conn = DB(env_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df4e3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise the Google Earth Engine connection.\n",
    "# Follow instructions on login prompt, if required.\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcfd378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDIT THIS CELL: All work is conducted under a unique session name\n",
    "session_name = \"boulia_test\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d7ce41",
   "metadata": {},
   "source": [
    "## Retrieve the session parameters from the database\n",
    "\n",
    "Edit the following cell to set the session name and retrieve the flood map parameters, including mapping grid and affected LGAs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9b6091",
   "metadata": {},
   "outputs": [],
   "source": [
    "tz = ZoneInfo(\"UTC\")\n",
    "midnight = datetime.min.time()\n",
    "\n",
    "# Query the floodmapping parameters from the DB\n",
    "query = (f\"SELECT flood_date_start, flood_date_end, \"\n",
    "         f\"ref_date_start, ref_date_end, bucket_uri \"\n",
    "         f\"FROM session_info \"\n",
    "         f\"WHERE session = %s;\")\n",
    "data = (session_name,)\n",
    "session_df = db_conn.run_query(query, data, fetch=True)\n",
    "flood_start_date = session_df.iloc[0][\"flood_date_start\"]\n",
    "flood_start_date = datetime.combine(flood_start_date, midnight).replace(tzinfo=tz)\n",
    "flood_end_date = session_df.iloc[0][\"flood_date_end\"]\n",
    "flood_end_date = datetime.combine(flood_end_date, midnight).replace(tzinfo=tz)\n",
    "ref_start_date = session_df.iloc[0][\"ref_date_start\"]\n",
    "ref_start_date = datetime.combine(ref_start_date, midnight).replace(tzinfo=tz)\n",
    "ref_end_date = session_df.iloc[0][\"ref_date_end\"]\n",
    "ref_end_date = datetime.combine(ref_end_date, midnight).replace(tzinfo=tz)\n",
    "bucket_uri = session_df.iloc[0][\"bucket_uri\"]\n",
    "\n",
    "# Query the selected grid positions and LGAs\n",
    "query = (f\"SELECT sp.patch_name, ST_AsText(gr.geometry), gr.lga_name22 \"\n",
    "         f\"FROM session_patches sp \"\n",
    "         f\"INNER JOIN grid_loc gr \"\n",
    "         f\"ON sp.patch_name = gr.patch_name \"\n",
    "         f\"WHERE sp.session = %s ;\")\n",
    "data = (session_name,)\n",
    "grid_sel_df = db_conn.run_query(query, data, fetch=True)\n",
    "\n",
    "# Format the results into a correct GeoDataFrame\n",
    "grid_sel_df['geometry'] = gpd.GeoSeries.from_wkt(grid_sel_df['st_astext'])\n",
    "grid_sel_df.drop(['st_astext'], axis=1, inplace = True)\n",
    "grid_sel_gdf = gpd.GeoDataFrame(grid_sel_df, geometry='geometry', crs=\"EPSG:4326\")\n",
    "grid_sel_gdf.drop_duplicates(subset=[\"patch_name\"], inplace=True)\n",
    "print(f\"[INFO] {len(grid_sel_gdf)} grid patches selected.\")\n",
    "\n",
    "# Query the affected LGA shapes\n",
    "lgas_sel_lst = grid_sel_df.lga_name22.unique().tolist()\n",
    "query = (f\"SELECT DISTINCT lga_name22, ST_AsText(geometry_col) \"\n",
    "         f\"FROM lgas_info \"\n",
    "         f\"WHERE lga_name22 IN %s ;\")\n",
    "data = (tuple(lgas_sel_lst),)\n",
    "lgas_sel_df = db_conn.run_query(query, data, fetch=True)\n",
    "\n",
    "# Format the results into a correct GeoDataFrame\n",
    "lgas_sel_df['geometry'] = gpd.GeoSeries.from_wkt(lgas_sel_df['st_astext'])\n",
    "lgas_sel_df.drop(['st_astext'], axis=1, inplace = True)\n",
    "lgas_sel_gdf = gpd.GeoDataFrame(lgas_sel_df, geometry='geometry', crs=\"EPSG:4326\")\n",
    "print(f\"[INFO] {len(lgas_sel_gdf)} LGAs affected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f4442c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the GCP paths\n",
    "rel_grid_path = \"0_DEV/1_Staging/GRID\"\n",
    "rel_operation_path = \"0_DEV/1_Staging/operational\"\n",
    "grid_path = os.path.join(bucket_uri, rel_grid_path).replace(\"\\\\\", \"/\")\n",
    "bucket_name = bucket_uri.replace(\"gs://\",\"\").split(\"/\")[0]\n",
    "session_path = os.path.join(bucket_uri,\n",
    "                            rel_operation_path,\n",
    "                            session_name).replace(\"\\\\\", \"/\")\n",
    "\n",
    "fs = utils.get_filesystem(grid_path)\n",
    "print(f\"[INFO] Will read inference products from:\\n\\t{grid_path}\")\n",
    "print(f\"[INFO] Will write mapping products to:\\n\\t{session_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7f19ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the database for successful maps of each mode\n",
    "query = (f\"SELECT patch_name, mode, data_path \"\n",
    "         f\"FROM postproc_temporal \"\n",
    "         f\"WHERE session = %s AND status = %s;\")\n",
    "data = (session_name, 1)\n",
    "temporal_df = db_conn.run_query(query, data, fetch=True)\n",
    "temporal_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5697361",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Select the files for the FLOOD map\n",
    "flood_df = temporal_df.loc[temporal_df[\"mode\"] == \"flood\"]\n",
    "geojsons_lst = [x for x in flood_df[\"data_path\"].values]\n",
    "num_files = len(geojsons_lst)\n",
    "if num_files == 0:\n",
    "    print(f\"\\t[ERR] No flooding files to merge!\")\n",
    "else:\n",
    "    print(f\"\\tSelected {num_files} grid patches for flood map.\")\n",
    "flood_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0137ecbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "postprocess.spatial_aggregation(geojsons_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22ce4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "floodmap = utils.read_geojson_from_gcp(geojsons_lst[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7b646b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_utils.plot_floodmap(floodmap) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae5b2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "floodmap.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d60f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "floodmap.to_crs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2024329b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (floodmapper)",
   "language": "python",
   "name": "floodmapper"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
