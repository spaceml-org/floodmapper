{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2757a77",
   "metadata": {},
   "source": [
    "# Initialise the FloodMapper GCP bucket\n",
    "\n",
    "Create the FloodMapper bucket structure and import the default model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3ed1f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary imports\n",
    "import os\n",
    "os.environ['USE_PYGEOS'] = '0'\n",
    "import fsspec\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from ml4floods.data import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0e833f",
   "metadata": {},
   "source": [
    "## Load environment and project details\n",
    "\n",
    "As with the other notebooks, we load credentials and project details from a hidden ```.env``` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49ef2bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Successfully loaded FloodMapper environment.\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables (including path to credentials) from '.env' file\n",
    "#env_file_path = \"../../.env\"\n",
    "env_file_path = \"../../.credentials\"\n",
    "\n",
    "assert load_dotenv(dotenv_path=env_file_path) == True, \"[ERR] Failed to load environment!\"\n",
    "assert \"GOOGLE_APPLICATION_CREDENTIALS\" in os.environ, \"[ERR] Missing $GOOGLE_APPLICATION_CREDENTIAL!\"\n",
    "assert \"GS_USER_PROJECT\" in os.environ, \"[ERR] Missing $GS_USER_PROJECT!\"\n",
    "key_file_path = os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]\n",
    "assert os.path.exists(key_file_path), f\"[ERR] Google credential key file does not exist: \\n{key_file_path} \"\n",
    "assert \"ML4FLOODS_BASE_DIR\" in os.environ, \"[ERR] Missing $ML4FLOODS_BASE_DIR!\"\n",
    "base_path = os.environ[\"ML4FLOODS_BASE_DIR\"]\n",
    "assert os.path.exists(base_path), f\"[ERR] Base path does not exist: \\n{base_path} \"\n",
    "print(\"[INFO] Successfully loaded FloodMapper environment.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5338373a",
   "metadata": {},
   "source": [
    "## Create 'folder' structures on the bucket\n",
    "\n",
    "Technically, the GCP bucket does not contain folders - it is a flat structure that contains only files. However, each filename includes the path as a way to emulate folders. In practise this means that folders spring into existence when files that include their path names are created.\n",
    "\n",
    "Here we will just write some temporary files as a check that we can access the bucket correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ac74c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bucket Name\n",
    "#bucket_name = \"gs://ml4floods_nema\"\n",
    "bucket_name = \"gs://floodmapper-test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4b5e05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required folders in the bucket\n",
    "dir_lst = [\"0_DEV/1_Staging/GRID\",\n",
    "           \"0_DEV/1_Staging/operational\",\n",
    "           \"0_DEV/2_Mart/2_MLModelMart\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53881cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating ''gs://floodmapper-test/0_DEV/1_Staging/GRID/tmp.txt''\n",
      "\tDoes file exist? -> True\n",
      "Creating ''gs://floodmapper-test/0_DEV/1_Staging/operational/tmp.txt''\n",
      "\tDoes file exist? -> True\n",
      "Creating ''gs://floodmapper-test/0_DEV/2_Mart/2_MLModelMart/tmp.txt''\n",
      "\tDoes file exist? -> True\n"
     ]
    }
   ],
   "source": [
    "# Loop through the directories and upload a temp file\n",
    "fs = utils.get_filesystem(bucket_name)\n",
    "for directory in dir_lst:\n",
    "    tmp_path = os.path.join(bucket_name, directory, \"tmp.txt\")\n",
    "    print(f\"Creating ''{tmp_path}''\")\n",
    "    with fs.open(tmp_path, \"w\") as fh:\n",
    "        fh.write(\"This is a placeholder.\\n\")\n",
    "    print(\"\\tDoes file exist? ->\", fs.exists(tmp_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558e1191",
   "metadata": {},
   "source": [
    "## Upload the model \n",
    "\n",
    "The trained model is distributed across several files under the 'WF2_unet_rbgiswirs' directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c50264f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying config.json ... done.\n",
      "Copying model.pt ... done.\n",
      "Copying test.json ... done.\n",
      "Copying val.json ... done.\n",
      "Copying checkpoint/epoch=6-step=14077.ckpt ... done.\n",
      "Copying checkpoint/epoch=9-step=23800.ckpt ... done.\n"
     ]
    }
   ],
   "source": [
    "# Assemble the source and destination paths\n",
    "model_name = \"WF2_unet_rbgiswirs\"\n",
    "model_path_gcp = os.path.join(bucket_name, \"0_DEV/2_Mart/2_MLModelMart/\", model_name)\n",
    "model_path_local = os.path.join(base_path, \"resources/models\", model_name)\n",
    "file_lst = [[\"config.json\", \"\"],\n",
    "            [\"model.pt\", \"b\"],\n",
    "            [\"test.json\", \"\"],\n",
    "            [\"val.json\", \"\"],\n",
    "            [\"checkpoint/epoch=6-step=14077.ckpt\", \"b\"],\n",
    "            [\"checkpoint/epoch=9-step=23800.ckpt\", \"b\"]]\n",
    "\n",
    "# Copy each file in turn\n",
    "for file_path, mode in file_lst:\n",
    "    full_gs_path = os.path.join(model_path_gcp, file_path)\n",
    "    full_local_path = os.path.join(model_path_local, file_path)\n",
    "    print(f\"Copying {file_path} ... \", end=\"\")\n",
    "    with open(full_local_path, \"r\" + mode) as f1:\n",
    "        content = f1.read()\n",
    "        with fs.open(full_gs_path, \"w\" + mode) as f2:\n",
    "            f2.write(content)\n",
    "    print(\"done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e04c16",
   "metadata": {},
   "source": [
    "You can check if the bucket contains the correct files at the [GCP Console Storage](https://console.cloud.google.com/storage) page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263c7141",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (nf_mac)",
   "language": "python",
   "name": "nf_mac"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
