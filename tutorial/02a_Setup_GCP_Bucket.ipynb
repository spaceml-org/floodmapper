{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2757a77",
   "metadata": {},
   "source": [
    "# Initialise the FloodMapper GCP bucket\n",
    "\n",
    "Create the FloodMapper bucket structure and import the default model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ed1f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary imports\n",
    "import os\n",
    "os.environ['USE_PYGEOS'] = '0'\n",
    "import fsspec\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from ml4floods.data import utils\n",
    "\n",
    "# Set bucket will not be requester pays\n",
    "utils.REQUESTER_PAYS_DEFAULT = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0e833f",
   "metadata": {},
   "source": [
    "## Load environment and project details\n",
    "\n",
    "As with the other notebooks, we load credentials and project details from a hidden ```.env``` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ef2bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables (including path to credentials) from '.env' file\n",
    "env_file_path = \"../.env\"\n",
    "\n",
    "# Uncomment for alternative version for Windows (r\"\" indicates raw string)\n",
    "#env_file_path = r\"C:/Users/User/floodmapper/.env\"\n",
    "\n",
    "assert load_dotenv(dotenv_path=env_file_path) == True, \"[ERR] Failed to load environment!\"\n",
    "assert \"GOOGLE_APPLICATION_CREDENTIALS\" in os.environ, \"[ERR] Missing $GOOGLE_APPLICATION_CREDENTIAL!\"\n",
    "assert \"GS_USER_PROJECT\" in os.environ, \"[ERR] Missing $GS_USER_PROJECT!\"\n",
    "key_file_path = os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]\n",
    "assert os.path.exists(key_file_path), f\"[ERR] Google credential key file does not exist: \\n{key_file_path} \"\n",
    "assert \"ML4FLOODS_BASE_DIR\" in os.environ, \"[ERR] Missing $ML4FLOODS_BASE_DIR!\"\n",
    "base_path = os.environ[\"ML4FLOODS_BASE_DIR\"]\n",
    "assert os.path.exists(base_path), f\"[ERR] Base path does not exist: \\n{base_path} \"\n",
    "bucket_name = os.environ[\"BUCKET_URI\"]\n",
    "assert bucket_name is not None and bucket_name != \"\", f\"Bucket name not defined {bucket_name}\"\n",
    "print(\"[INFO] Successfully loaded FloodMapper environment.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5338373a",
   "metadata": {},
   "source": [
    "## Create 'folder' structures on the bucket\n",
    "\n",
    "Technically, the GCP bucket does not contain folders - it is a flat structure that contains only files. However, each filename includes the path as a way to emulate folders. In practise this means that folders spring into existence when files that include their path names are created.\n",
    "\n",
    "Here we will just write some temporary files as a check that we can access the bucket correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b5e05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required folders in the bucket\n",
    "dir_lst = [\"0_DEV/1_Staging/GRID\",\n",
    "           \"0_DEV/1_Staging/operational\",\n",
    "           \"0_DEV/2_Mart/2_MLModelMart\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53881cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the directories and upload a temp file\n",
    "fs = utils.get_filesystem(bucket_name)\n",
    "for directory in dir_lst:\n",
    "    tmp_path = os.path.join(bucket_name, directory, \"tmp.txt\").replace(\"\\\\\",\"/\")\n",
    "    print(f\"Creating ''{tmp_path}''\")\n",
    "    with fs.open(tmp_path, \"w\") as fh:\n",
    "        fh.write(\"This is a placeholder.\\n\")\n",
    "    print(\"\\tDoes file exist? ->\", fs.exists(tmp_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0309f9",
   "metadata": {},
   "source": [
    "The block above should report 'True' that the three files now exist on the bucket. If an error is reported, it is likely due to a problem with credentials. Check in the ```.env``` file that:\n",
    " * The path to the JSON key file is correct.\n",
    " * The correct key file is being used (inspect the key file for the correct project name).\n",
    " * The project name is correct."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558e1191",
   "metadata": {},
   "source": [
    "## Upload the model \n",
    "\n",
    "The trained model is distributed across several files under the 'WF2_unet_rbgiswirs' directory. The next block of code uploads these files to the GCP bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50264f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assemble the source and destination paths\n",
    "model_name = \"WF2_unet_rbgiswirs\"\n",
    "model_path_gcp = os.path.join(bucket_name, \"0_DEV/2_Mart/2_MLModelMart/\", model_name).replace(\"\\\\\",\"/\")\n",
    "model_path_local = os.path.join(base_path, \"resources/models\", model_name).replace(\"\\\\\",\"/\")\n",
    "file_lst = [[\"config.json\", \"\"],\n",
    "            [\"model.pt\", \"b\"],\n",
    "            [\"test.json\", \"\"],\n",
    "            [\"val.json\", \"\"],\n",
    "            [\"checkpoint/epoch=6-step=14077.ckpt\", \"b\"],\n",
    "            [\"checkpoint/epoch=9-step=23800.ckpt\", \"b\"]]\n",
    "\n",
    "# Copy each file in turn\n",
    "for file_path, mode in file_lst:\n",
    "    full_gs_path = os.path.join(model_path_gcp, file_path).replace(\"\\\\\",\"/\")\n",
    "    full_local_path = os.path.join(model_path_local, file_path).replace(\"\\\\\",\"/\")\n",
    "    print(f\"Copying {file_path} ... \", end=\"\")\n",
    "    with open(full_local_path, \"r\" + mode) as f1:\n",
    "        content = f1.read()\n",
    "        with fs.open(full_gs_path, \"w\" + mode) as f2:\n",
    "            f2.write(content)\n",
    "    print(\"done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e04c16",
   "metadata": {},
   "source": [
    "You can check if the bucket contains the correct files at the [GCP Console Storage](https://console.cloud.google.com/storage) page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263c7141",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (floodmapper)",
   "language": "python",
   "name": "floodmapper"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
